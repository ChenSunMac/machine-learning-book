## 决策树 数学模型及推导

给定训练数据
$$x_i \in R^n, i=1,…,l$$  
以及标签好的y 
$$y \in R^l$$, 
A **decision tree** recursively partitions the space such that the samples with the same labels are grouped together. 
决策树递归的将这些数据和对应的标签划分到一起，递归的建树。


### ID3 算法
在这里，我们的输入是m个样本，实际上是m行的table，每个样本有n个离散特征，也就是n列，特征集合为A，输出为决策树T。
算法过程如下：
1. 初始化信息增益的阈值 $$\epsilon$$
2. 判断样本是否为同一类输出 $$D_i$$ (有没有到叶节点)，如果是则return 单节点树T，标记为$$D_i$$
3. 判断当前特征 A 是否为空，如果是则 return 单节点树 T，此时没有特征可以分了，所以标记样本输出类别D实例数最多的类别。
4. 计算A中的各个特征 （一共n个）对输出D的信息增益，选择信息增益最大的特征$$A_g$$
5. 判断$$A_g$$的信息增益小于阈值$$\epsilon$$, 则返回单节点T，标记类别为样本输出类别D实例最多的的类别，同3
6. 否则，按照特征$$A_g$$的不同取值$$A_{gi}$$将对应的样本输出D分成不同的类别$$D_i$$。每个类别产生一个子节点。对应特征值为$$A_{gi}$$。返回增加了节点的数T




